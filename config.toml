[common]
# number of core threads for the async runtime, is recommended to be set double of CPU cores for I/O bound tasks
# if not set, default is number of CPU cores
#core_threads = 8

[node]
id = "001"

[service.restful]
ip = "0.0.0.0"
port = 1107

[mqtt.listener.tcp]
host = "0.0.0.0"
port = 1883

[mqtt.listener.tcp_tls]
host = "127.0.0.1"
port = 8883
cert_path = "certs/server.crt"
key_path = "certs/server.key"

[mqtt.listener.ws]
host = "127.0.0.1"
port = 8081
path = "/mqtt"

[mqtt.listener.wss]
host = "127.0.0.1"
port = 8082
path = "/mqtt"
cert_path = "certs/server.crt"
key_path = "certs/server.key"

[mqtt.settings]
# keep alive interval in seconds, if client specified value is smaller, override it
keep_alive = 60
# maximum topic length in characters, must be between 1 and 65535
max_topic_length = 256
# session expiry interval in seconds, 0 means use client specified value, >0 means if client specified value is larger, override it, avoid unlimited session
# default 7 days: 7 * 24 * 60 * 60 = 604800
session_expiry_interval = 604800
# maximum in-flight messages, must be between 1 and 65535, if client specified value is larger, override it
max_receive_queue = 128
# maximum packet size in bytes, default is 2MB, 2 * 1024 * 1024, must be between 1 and 268435455, if client specified value is larger, override it
max_packet_size = 2097152
# interval to resend QoS 1/2 messages in seconds
resend_interval = 2
# maximum stored messages per client for offline clients, must be between 0 and 1000000, 0 means no limit
max_store_msgs_per_client = 128
# interval to clean up expired retained messages in seconds
retain_cleanup_interval = 5
# interval to clean up expired sessions for offline clients in seconds
session_cleanup_interval = 60
# maximum number of topic aliases per client, must be between 0 and 65535, 0 means topic alias feature is disabled, if client specified value is larger, override it
topic_alias_maximum = 30

[mqtt.strategy]
# strategy for shared subscription message delivery, "round_robin" or "random"
shared_delivery = "round_robin"

[service.sparkplug_b]
enable = true
application_id = "axonmq_sparkplug_b_application"

[service.sparkplug_b.rebirth_on_error]
# whether to rebirth on sequence mismatch error, Not Implemented yet
on_seq_mismatch = false
# whether to rebirth on malformed payload error
on_malformed_payload = true

# router modules, define the processing chains for different topics or clients
# topic is necessary, client_id is optional
# if multiple routers match, all matching routers will be applied in order of definition
# if no router matches, the message will be delivered to the client directly
[[router]]
topic = "sensors/+/temperature"
chain = ["logger"]

[[router]]
topic = "sensors/+/humidity"
client_id = "sensor_hub_001"
chain = ["logger"]

[[router]]
topic = "chain/example"
chain = ["logger"]

[[router]]
topic = "chain/+"
chain = ["logger"]

# processing chains, define the sequence of processors to apply
# each chain must have a unique name
# processors are identified by their UUIDs defined in the processor modules
# if message is dropped by any processor or rejected by the chain, it will not be delivered to the client
# if message through the chain is accepted and last processor returns message, it will be delivered to the client
[[chain]]
name = "logger"
processors = ["10495c56-1922-414e-acfe-0bffafaa5d12", "223e4567-e89b-12d3-a456-426614174000"]
delivery = true                  # false or true, false means do not deliver to client, true means deliver to client if message is not dropped

# processor modules, define the processors available for use in chains
# each processor must have a unique UUID
# processor supports the native Rust Implementation and WebAssembly (WASM) implementation
[[processor]]
uuid = "10495c56-1922-414e-acfe-0bffafaa5d12"
config = { type = "logger", level = "info" }

[[processor]]
uuid = "223e4567-e89b-12d3-a456-426614174000"
config = { type = "wasm", path = "wasm/example.wasm", cfg = "{}" }


# --- Republish Processor Example ---
# The following example demonstrates how to use the republish processor.
# It captures all messages from "raw/data/#", and republishes them
# to a new topic "processed/data" with a fixed QoS of 1.

[[router]]
topic = "raw/data/#"
chain = ["republish_chain"]

[[chain]]
name = "republish_chain"
processors = ["a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11"] # This UUID must match the processor below
delivery = true # Ensures the modified message is sent to the matcher for publishing

[[processor]]
uuid = "a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11"
config = { type = "republish", topic = "processed/data/{{ client_id }}", qos = 1 }


# --- Webhook Processor Example ---
# The following example demonstrates how to use the webhook processor.
# It captures all messages from "webhook/#", and sends them to a specified HTTP endpoint.
# Use https://webhook.site to generate a test URL for receiving the webhook requests.

[[router]]
topic = "webhook/#"
chain = ["webhook_chain"]

[[chain]]
name = "webhook_chain"
processors = ["b0eebc99-9c0b-4ef8-bb6d-6bb9bd380a12"]
delivery = true

[[processor]]
uuid = "b0eebc99-9c0b-4ef8-bb6d-6bb9bd380a12"
config = { type = "webhook", url = "https://webhook.site/9e55311f-a3fd-4459-999f-675a8dfc31ac", method = "POST", headers = { "Content-Type" = "application/json" }, body_template = '''{ "topic": "{{ topic }}", "client_id": "{{ client_id }}", "payload_as_json": {{ payload }}, "payload_as_string": "{{ raw_payload }}" }, "time": "{{ payload.time }}"''' }


# --- JsonTransform Processor Example ---
# The following example demonstrates how to chain processors.
# 1. It captures messages from "raw/json/#".
# 2. A `json-transform` processor reshapes the JSON payload.
# 3. A `republish` processor takes the modified message and publishes it to "processed/json/{{ client_id }}".

[[router]]
topic = "raw/json/#"
chain = ["transform_and_republish_chain"]

[[chain]]
name = "transform_and_republish_chain"
processors = [
"f47ac10b-58cc-4372-a567-0e02b2c3d479", # UUID for the transformer
"98a34e3d-ff2d-4dc9-a52b-34a5c2c3d480"  # UUID for the republisher
]
delivery = true

[[processor]]
uuid = "f47ac10b-58cc-4372-a567-0e02b2c3d479"
config = { type = "json_transform", template = '''
{
"device": "{{ client_id }}",
"original_topic": "{{ topic }}",
"data": {{ payload }},
"processed_at": "{{ now() | date("%Y-%m-%d %H:%M:%S %z") }}"
"processed_at1": "{{ now() }}"
}
'''}

[[processor]]
uuid = "98a34e3d-ff2d-4dc9-a52b-34a5c2c3d480"
config = { type = "republish", topic = "processed/json/{{ client_id }}" }

# --- Filter Processor Example ---
# The following example demonstrates how to use the filter processor.
# 1. It captures messages from "telemetry/thermostat".
# 2. A `filter` processor checks if the temperature is high. 
#    It drops the message if the temperature is NOT high (i.e., <= 40).
# 3. If the message passes the filter, a `republish` processor sends it to the "alerts/high_temp" topic.

[[router]]
topic = "telemetry/thermostat"
chain = ["high_temp_alert_chain"]

[[chain]]
name = "high_temp_alert_chain"
processors = [
"44444444-4444-4444-4444-444444444444", # UUID for the filter
"55555555-5555-5555-5555-555555555555"  # UUID for the republisher
]
delivery = true

# Note: The condition is for KEEPING the message.
# So, we drop it if the temperature is defined and less than or equal to 40
# If the payload doesn't have a 'temperature' field, pass it through but log a warning.
[[processor]]
uuid = "44444444-4444-4444-4444-444444444444"
config = { type = "filter", condition = "{{ payload.temperature is not defined or payload.temperature > 40 }}", on_error_pass = true }

[[processor]]
uuid = "55555555-5555-5555-5555-555555555555"
config = { type = "republish", topic = "alerts/high_temp" }

# --- Anomaly Detector Processor Example ---
# The following example demonstrates how to use the anomaly_detector processor.
# 1. It captures pressure readings from the "telemetry/pressure_sensor" topic.
# 2. The processor maintains a moving average of the last 10 values for each client.
# 3. If a new value deviates from the average by more than 2.0 standard deviations,
#    it logs a warning message with a detailed anomaly report.

[[router]]
topic = "telemetry/pressure_sensor"
chain = ["pressure_anomaly_detection_chain"]

[[chain]]
name = "pressure_anomaly_detection_chain"
processors = ["a1b2c3d4-e5f6-a7b8-c9d0-e1f2a3b4c5d6"] # UUID for the anomaly detector
delivery = true # The original message will still be delivered to subscribers

[[processor]]
uuid = "a1b2c3d4-e5f6-a7b8-c9d0-e1f2a3b4c5d6"
config = { type = "anomaly_detector", value_selector = "payload.pressure", series_id = "{{ client_id }}", strategy = { type = "moving_average", window_size = 10, deviation_factor = 2.0 } }
